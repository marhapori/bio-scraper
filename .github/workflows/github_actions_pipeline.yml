name: Product Data Scraper Pipeline

on:
  push:
    branches:
      - main
  schedule:
    - cron: '0 3 * * *'  # daily at 3:00 UTC (5:00 Budapest)
  workflow_dispatch: {}

jobs:
  setup-and-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Lint code with flake8
        run: |
          pip install flake8
          flake8 . --max-line-length=120

      - name: Run unit tests
        run: |
          pytest --maxfail=1 --disable-warnings -q

  run-scraper:
    needs: setup-and-test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run scraper to fetch product data
        run: |
          python google_scraper_example.py

      - name: Archive results
        uses: actions/upload-artifact@v2
        with:
          name: scraped-product-data
          path: |
            product_data_raw.csv
            product_data_with_descriptions.csv
