name: Product Data Scraper Pipeline

on:
  push:
    branches:
      - main
  schedule:
    - cron: '0 3 * * *'  # minden nap 3:00 UTC (5:00 Budapest)
  workflow_dispatch: {}

jobs:
  setup-and-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      - uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
      - run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - run: |
          pip install flake8
          flake8 . --max-line-length=120
      - run: pytest --maxfail=1 --disable-warnings -q

  run-scraper:
    needs: setup-and-test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      - run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - run: python google_scraper_example.py
      - uses: actions/upload-artifact@v2
        with:
          name: scraped-product-data
          path: |
            product_data_raw.csv
            product_data_with_descriptions.csv
